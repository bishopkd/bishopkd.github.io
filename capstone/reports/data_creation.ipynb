{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Import packages and create global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import textract\n",
    "from textblob import TextBlob, Word\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/'\n",
    "epub_path = \"/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/_epub_working/\"\n",
    "txt_path = \"/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/_txt/\"\n",
    "test_path = '/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/test_hold_out/'\n",
    "folders = ['sci-fi_top','sci-fi_flop','romance_top','romance_flop']\n",
    "folders2 = ['other']\n",
    "check_words = ['acknowledgements','table of contents','about the author', 'appendix', \n",
    "               'copyright','isbn','by this author', 'chapter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load profanity file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curses = pd.read_csv(path + 'other/profanity.csv')\n",
    "curses.drop('Unnamed: 1', inplace=True, axis=1)\n",
    "bad_words = curses.word.T.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract text from epub files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text file creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop through files in directory, convert file, save file in new folder\n",
    "def create_text_files(epub_path,txt_path):\n",
    "    for epub in os.listdir(epub_path):\n",
    "        try:\n",
    "            convert_epub_to_text(epub_path, epub, txt_path)\n",
    "        except:\n",
    "            print epub, \"failed\"\n",
    "            \n",
    "# function to extract text from epub\n",
    "def convert_epub_to_text(epub_path, epub_file, txt_path):\n",
    "    clean_text = ''\n",
    "    text_name = epub_file.replace(' ','_')[:-4]+'txt' #clean up filename and change file extention\n",
    "    \n",
    "    text = textract.process(epub_path+epub_file,encoding='utf_8') #extract text from epub\n",
    "    clean_text = text.decode('ascii', 'ignore').replace('\\n',' ') #trip out the unicode and return characters\n",
    "\n",
    "    text_file = open(txt_path+text_name, 'w') #save as text file\n",
    "    text_file.write(clean_text)\n",
    "    text_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_text_files(epub_path,txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split each file into 10 sub-chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_text_files(epub_path,txt_path):\n",
    "    for txt_file in os.listdir(epub_path):\n",
    "        if txt_file[:1]!='.':\n",
    "            try:\n",
    "                split(epub_path, txt_file, txt_path)\n",
    "            except:\n",
    "                print txt_file, \"failed\"\n",
    "\n",
    "def split(in_path, txt_file, out_path):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    sent_detect = PunktSentenceTokenizer()\n",
    "    text  = open(in_path + txt_file, 'r').read()\n",
    "    utext = text.decode('ascii', 'ignore').replace('\\n',' ').replace('\\r','').replace('-',' ').replace('.','. ')\n",
    "    sentences = sent_detect.sentences_from_text(utext)\n",
    "    \n",
    "    chunksize = len(sentences)/10\n",
    "    fid = 1\n",
    "\n",
    "    with open(in_path + txt_file) as infile:\n",
    "        f = open(out_path + '%s%d.txt' % (txt_file[:-4],fid), 'w')\n",
    "        for i,line in enumerate(sentences):\n",
    "            f.write(line)\n",
    "            if i%chunksize==0 and i!=0 and fid!=10:\n",
    "                f.close()\n",
    "                fid += 1\n",
    "                f = open(out_path + '%s%d.txt' % (txt_file[:-4],fid), 'w')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_text_files(epub_path,txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create the dataframes for the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# master function that calls functions below\n",
    "def create_data(path,folders,df):\n",
    "    df_name = df\n",
    "    df = create_df_from_files(path, folders) # create df and initial binary indicators\n",
    "    create_metrics(df)                       # create metric columns (this runs forever)\n",
    "    df.to_csv(path + df_name + '.csv')       # saves df as csv so we don't have to do the above again\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training data  - note: this takes many moons to run\n",
    "df = create_data(path,folders,'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create testing data\n",
    "df_test = create_data(test_path,folders,'df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create hold-out data\n",
    "df_other = create_data(test_path,folders2,'df_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check for front and back matter\n",
    "validate_content(df,check_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions that perform the above magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load txt files into dataframe, \n",
    "# give each entry a best_selling 1/0 entry and a sci_fi 1/0 (0=romance) indicator\n",
    "def create_df_from_files(path, folders):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for folder in folders:\n",
    "        if folder[-3:]=='top':\n",
    "            bs = 1\n",
    "        else:\n",
    "            bs = 0\n",
    "        if folder[:3]=='sci':\n",
    "            sf = 1\n",
    "        else:\n",
    "            sf = 0\n",
    "\n",
    "        for text_file in os.listdir(path+folder+'/'):\n",
    "            full_path = path + folder + '/' + text_file\n",
    "            if text_file.endswith((\".txt\")):\n",
    "                text  = open(full_path, 'r').read()\n",
    "                temp = pd.DataFrame({\n",
    "                        'best_seller': bs,\n",
    "                        'sci_fi': sf,\n",
    "                        'title': text_file[:-4].replace('_',' ').replace('-',' - '),\n",
    "                        'body': text.decode('ascii', 'ignore').replace('\\n',' ').replace('\\r','').replace('-',' ').replace('?','? ').replace('.','. ')}, \n",
    "                                    index=[0])\n",
    "                df = pd.concat([df, temp])\n",
    "\n",
    "    df = df.reset_index() # because index=[0]\n",
    "    del df['index']\n",
    "    return df\n",
    "\n",
    "# check for front and back matter in body\n",
    "# remaining issues are intentional usage in the body\n",
    "def validate_content(df, check_words):\n",
    "    for i in range(0,len(df)):\n",
    "        for word in check_words:\n",
    "            if word in df.iloc[i,1].lower():\n",
    "                print df.ix[i,3], ' : ', word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function bank for creating metrics\n",
    "\n",
    "def avg_sentence_len(text):\n",
    "    word_counts = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    sent_detect = PunktSentenceTokenizer()\n",
    "    sentences = sent_detect.sentences_from_text(text)\n",
    "    for sentence in sentences:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        word_counts.append(len(words))\n",
    "    avg_word_count = sum(word_counts)/len(word_counts)  \n",
    "    return avg_word_count\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "def get_token_words(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    return words\n",
    "\n",
    "def word_count(text):\n",
    "    words = get_token_words(text)\n",
    "    return len(words)\n",
    "\n",
    "def avg_word_len(text):\n",
    "    letter_counts = []\n",
    "    words = get_token_words(text)\n",
    "    for word in words:\n",
    "        letter_counts.append(len(word))\n",
    "    avg_word_len = sum(letter_counts)/len(letter_counts)\n",
    "    return avg_word_len\n",
    "\n",
    "def profanity_counter(text):\n",
    "    i=0\n",
    "    words = get_token_words(text)\n",
    "    for word in words:\n",
    "        if word in bad_words:\n",
    "            i+=1       \n",
    "    return i\n",
    "\n",
    "def lex_div(text):\n",
    "    words = get_token_words(text)\n",
    "    lexical_diversity = 1.0 * len(set(words)) / len(words)\n",
    "    return lexical_diversity\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "def to_blob(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob\n",
    "\n",
    "def assign_polarity(text):\n",
    "    blob = to_blob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def assign_subjectivity(text):\n",
    "    blob = to_blob(text)\n",
    "    return blob.sentiment.subjectivity\n",
    "\n",
    "#---------------------------------\n",
    "\n",
    "def parse_pos(df,field):\n",
    "    for i in range(0,len(df)):\n",
    "        blob = TextBlob(df.ix[i,field])\n",
    "        tags = blob.tags\n",
    "        df_tags = pd.DataFrame(tags)\n",
    "        df_tags = df_tags.groupby([1]).count().reset_index() # create a count of POS tags \n",
    "\n",
    "        verbs=[] # create verb-only list\n",
    "        for word,pos in tags:\n",
    "            if pos[:2] == 'VB':\n",
    "                try:\n",
    "                    verbs.append((word, wordnet.synsets(word,'v')[0].lexname())) # get lexical name for each verb\n",
    "                except:\n",
    "                    continue\n",
    "       \n",
    "        df_verbs = pd.DataFrame(verbs)\n",
    "        df_verbs = df_verbs.groupby([1]).count().reset_index() # create a count of verb subtype tags\n",
    "                \n",
    "        df_tags = pd.concat([df_tags,df_verbs], axis=0).reset_index()            # concat the pos df and the verb df\n",
    "        del df_tags['index']\n",
    "\n",
    "        df.ix[i,'verb_count'] = len(verbs)\n",
    "        for x in range(0,len(df_tags)):                            # add these as new columns to df           \n",
    "                df.ix[i, df_tags.ix[x,1] ] = df_tags.ix[x,0]   \n",
    "        df.fillna(0,inplace=True)\n",
    "\n",
    "            \n",
    "#-----------------------------------\n",
    "   \n",
    "def normalize_pos(df):\n",
    "    for row in range(0,len(df)):\n",
    "        for col in range(11,len(df.columns)):\n",
    "            if df.columns[col][:5]=='verb.':        # if one of the verb categories div by verb count\n",
    "                df.iloc[row, col] = df.iloc[row,col]/df.ix[row,'verb_count']\n",
    "            else:\n",
    "                if df.columns[col][:5]!='verb_':    # if not div by total word count\n",
    "                    df.iloc[row, col] = df.iloc[row,col]/df.ix[row,'word_count']\n",
    "            \n",
    "#-----------------------------------\n",
    "\n",
    "def clean_more(text):\n",
    "    return text.replace('.','. ').replace('`',' ').replace('*','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new columns of metrics and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_metrics(df):\n",
    "    df['body'] = df['body'].map(clean_more)\n",
    "    df['avg_sent_len'] = df['body'].map(avg_sentence_len)\n",
    "    df['word_count'] = df['body'].map(word_count)\n",
    "    df['avg_word_len'] = df['body'].map(avg_word_len)\n",
    "    df['lex_diversity'] = df['body'].map(lex_div)\n",
    "    df['polarity'] = df['body'].map(assign_polarity)\n",
    "    df['subjectivity'] = df['body'].map(assign_subjectivity)\n",
    "    df['profanity'] = df['body'].map(profanity_counter)\n",
    "    df['profane'] = 1. * df['profanity']/df['word_count']\n",
    "    parse_pos(df,'body')\n",
    "    normalize_pos(df)\n",
    "    \n",
    "    df.rename(columns={'CC':'conj_coord', 'CD':'number', 'DT':'determiner', 'EX':'exist_there',\n",
    "                  'FW':'foreign_word','IN':'conj_sub_prep','JJ':'adj','JJR':'adj_compare',\n",
    "                 'JJS':'adj_sup','MD':'verb_aux',  'NN':'noun','NNP':'noun_prop',\n",
    "                'NNPS':'noun_prop_pural',  'NNS':'noun_plural', 'PDT':'predeterm','PRP':'pronoun_pers',\n",
    "                'PRP$':'pronoun_poss',  'RB':'adv','RBR':'adv_compare','RBS':'adv_sup',\n",
    "                  'RP':'adv_part', 'TO':'inf_to',  'UH':'interject','VB':'verb_base',\n",
    "                 'VBD':'verb_past','VBG':'verb_ger','VBN':'verb_pp','VBP':'verb_sing_pres',\n",
    "                 'VBZ':'verb_3rd_sing_pres','WDT':'wh_determ','WP':'wh_pronoun','WP$':'wh_poss',\n",
    "                 'WRB':'wh_adv','POS':'poss_ending','SYM':'symbol','LS':'list_marker'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Double check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_seller</th>\n",
       "      <th>body</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>verb.emotion</th>\n",
       "      <th>verb.motion</th>\n",
       "      <th>verb.perception</th>\n",
       "      <th>verb.possession</th>\n",
       "      <th>verb.social</th>\n",
       "      <th>verb.stative</th>\n",
       "      <th>verb.weather</th>\n",
       "      <th>wh_poss</th>\n",
       "      <th>poss_ending</th>\n",
       "      <th>list_marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prologue  The sun is always just about to ris...</td>\n",
       "      <td>1</td>\n",
       "      <td>2312 - kim stanley robinson1</td>\n",
       "      <td>13</td>\n",
       "      <td>14559</td>\n",
       "      <td>4</td>\n",
       "      <td>0.223092</td>\n",
       "      <td>0.089476</td>\n",
       "      <td>0.486843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031551</td>\n",
       "      <td>0.133513</td>\n",
       "      <td>0.065025</td>\n",
       "      <td>0.089265</td>\n",
       "      <td>0.086572</td>\n",
       "      <td>0.239708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>That wayis this what love was, this desire for...</td>\n",
       "      <td>1</td>\n",
       "      <td>2312 - kim stanley robinson10</td>\n",
       "      <td>18</td>\n",
       "      <td>18721</td>\n",
       "      <td>4</td>\n",
       "      <td>0.204102</td>\n",
       "      <td>0.101801</td>\n",
       "      <td>0.465005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031855</td>\n",
       "      <td>0.129503</td>\n",
       "      <td>0.054183</td>\n",
       "      <td>0.115808</td>\n",
       "      <td>0.093778</td>\n",
       "      <td>0.252754</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_seller                                               body  sci_fi  \\\n",
       "0            1   Prologue  The sun is always just about to ris...       1   \n",
       "1            1  That wayis this what love was, this desire for...       1   \n",
       "\n",
       "                           title  avg_sent_len  word_count  avg_word_len  \\\n",
       "0   2312 - kim stanley robinson1            13       14559             4   \n",
       "1  2312 - kim stanley robinson10            18       18721             4   \n",
       "\n",
       "   lex_diversity  polarity  subjectivity     ...       verb.emotion  \\\n",
       "0       0.223092  0.089476      0.486843     ...           0.031551   \n",
       "1       0.204102  0.101801      0.465005     ...           0.031855   \n",
       "\n",
       "   verb.motion  verb.perception  verb.possession  verb.social  verb.stative  \\\n",
       "0     0.133513         0.065025         0.089265     0.086572      0.239708   \n",
       "1     0.129503         0.054183         0.115808     0.093778      0.252754   \n",
       "\n",
       "   verb.weather  wh_poss  poss_ending  list_marker  \n",
       "0      0.000000      0.0          0.0          0.0  \n",
       "1      0.000893      0.0          0.0          0.0  \n",
       "\n",
       "[2 rows x 63 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_seller</th>\n",
       "      <th>body</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>verb.creation</th>\n",
       "      <th>verb.emotion</th>\n",
       "      <th>verb.motion</th>\n",
       "      <th>verb.perception</th>\n",
       "      <th>verb.possession</th>\n",
       "      <th>verb.social</th>\n",
       "      <th>verb.stative</th>\n",
       "      <th>verb.weather</th>\n",
       "      <th>poss_ending</th>\n",
       "      <th>list_marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prologue: Mei  Mei?Miss Carrie said.  Please ...</td>\n",
       "      <td>1</td>\n",
       "      <td>caliban war - james corey1</td>\n",
       "      <td>12</td>\n",
       "      <td>18326</td>\n",
       "      <td>4</td>\n",
       "      <td>0.204245</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013251</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.149882</td>\n",
       "      <td>0.058893</td>\n",
       "      <td>0.096290</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.201708</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>There was no way to know what would be on the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>caliban war - james corey10</td>\n",
       "      <td>11</td>\n",
       "      <td>16870</td>\n",
       "      <td>4</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>0.022211</td>\n",
       "      <td>0.436823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>0.022176</td>\n",
       "      <td>0.158825</td>\n",
       "      <td>0.059335</td>\n",
       "      <td>0.102787</td>\n",
       "      <td>0.086605</td>\n",
       "      <td>0.194486</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_seller                                               body  sci_fi  \\\n",
       "0            1   Prologue: Mei  Mei?Miss Carrie said.  Please ...       1   \n",
       "1            1  There was no way to know what would be on the ...       1   \n",
       "\n",
       "                         title  avg_sent_len  word_count  avg_word_len  \\\n",
       "0   caliban war - james corey1            12       18326             4   \n",
       "1  caliban war - james corey10            11       16870             4   \n",
       "\n",
       "   lex_diversity  polarity  subjectivity     ...       verb.creation  \\\n",
       "0       0.204245  0.016294      0.449777     ...            0.013251   \n",
       "1       0.189034  0.022211      0.436823     ...            0.008690   \n",
       "\n",
       "   verb.emotion  verb.motion  verb.perception  verb.possession  verb.social  \\\n",
       "0      0.020024     0.149882         0.058893         0.096290     0.085100   \n",
       "1      0.022176     0.158825         0.059335         0.102787     0.086605   \n",
       "\n",
       "   verb.stative  verb.weather  poss_ending  list_marker  \n",
       "0      0.201708      0.000883          0.0          0.0  \n",
       "1      0.194486      0.001498          0.0          0.0  \n",
       "\n",
       "[2 rows x 63 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_seller</th>\n",
       "      <th>body</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>verb.creation</th>\n",
       "      <th>verb.emotion</th>\n",
       "      <th>verb.motion</th>\n",
       "      <th>verb.perception</th>\n",
       "      <th>verb.possession</th>\n",
       "      <th>verb.social</th>\n",
       "      <th>verb.stative</th>\n",
       "      <th>verb.weather</th>\n",
       "      <th>poss_ending</th>\n",
       "      <th>wh_poss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Flirtation lasts the brief flutter of a butter...</td>\n",
       "      <td>0</td>\n",
       "      <td>aquarian awakenings - lisa shea</td>\n",
       "      <td>11</td>\n",
       "      <td>29514</td>\n",
       "      <td>4</td>\n",
       "      <td>0.152504</td>\n",
       "      <td>0.090507</td>\n",
       "      <td>0.464572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010716</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>0.169815</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.102979</td>\n",
       "      <td>0.078097</td>\n",
       "      <td>0.210498</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>She got of the plane and the wall of damp w...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaNoWriMojo - some chump</td>\n",
       "      <td>10</td>\n",
       "      <td>47843</td>\n",
       "      <td>4</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>0.078923</td>\n",
       "      <td>0.498603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.050776</td>\n",
       "      <td>0.119286</td>\n",
       "      <td>0.055104</td>\n",
       "      <td>0.116542</td>\n",
       "      <td>0.097857</td>\n",
       "      <td>0.258841</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_seller                                               body  sci_fi  \\\n",
       "0            0  Flirtation lasts the brief flutter of a butter...       0   \n",
       "1            0     She got of the plane and the wall of damp w...       0   \n",
       "\n",
       "                             title  avg_sent_len  word_count  avg_word_len  \\\n",
       "0  aquarian awakenings - lisa shea            11       29514             4   \n",
       "1         NaNoWriMojo - some chump            10       47843             4   \n",
       "\n",
       "   lex_diversity  polarity  subjectivity    ...     verb.creation  \\\n",
       "0       0.152504  0.090507      0.464572    ...          0.010716   \n",
       "1       0.134502  0.078923      0.498603    ...          0.011190   \n",
       "\n",
       "   verb.emotion  verb.motion  verb.perception  verb.possession  verb.social  \\\n",
       "0      0.021431     0.169815         0.070287         0.102979     0.078097   \n",
       "1      0.050776     0.119286         0.055104         0.116542     0.097857   \n",
       "\n",
       "   verb.stative  verb.weather  poss_ending   wh_poss  \n",
       "0      0.210498      0.006357     0.000000  0.000000  \n",
       "1      0.258841      0.001583     0.000314  0.000084  \n",
       "\n",
       "[2 rows x 62 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
